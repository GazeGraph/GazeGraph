# DesktopActivity Eye Tracking Dataset

This repository contains download links and the introduction of the DesktopActivity Eye Tracking dataset collected in the ACM SenSys 2020 paper: "GazeGraph: Graph-based Few-Shot Cognitive Context Sensingfrom Human Visual Behavior" [Guohao Lan](https://guohao.netlify.app/), [Bailey Heit](https://www.linkedin.com/in/bailey-heit-b35a23152/), [Tim Scargill](https://sites.duke.edu/timscargill/), and [Maria Gorlatova](https://maria.gorlatova.com/). 

For questions on this repository or the related paper, please contact Guohao Lan via (guohao DOT lan AT duke DOT edu).

**Summary**:

* [Dataset Information](#1)
* [Dataset Download](#2)
* [Citation](#3)
* [Acknowledgments](#4)

## 1. <span id="1">Dataset Information</span>

The dataset is collected from eight subjects (four female and four male, aged between 24 and 35; all subjects are fluent in English, with Spanish (1), English (2), and Chinese (5) as their first language) using the [Pupil Core](https://pupil-labs.com/products/core/) eye tracker. The study is approved by our institution's Institutional Review Board. 

During data collection, the subjects wear the eye tracker and sit in front of the computer screen (a 34-inch display) at a distance of approximately~50cm. We conduct the manufacturer's default on-screen five-points calibration for each of the subjects. Note that only one calibration is needed per subject, and the subjects can move their heads and upper bodies freely during the experiment. 

## 2. <span id="1">Download Dataset</span>

## 3. <span id="1">Citation</span>


## Examples of the data collection process for the DesktopActivity dataset
We use the Pupil Core head-mounted eye tracker to collect the eye movement behavior of eight subjects when performing six desktop activities. To give an example of how the data collection was performed, we share the videos that are captured by the scene camera of the eye tracker when a subject is performing the six activities: https://www.dropbox.com/sh/brw160oe48vcxfj/AACk4eQ0ThLdrppmaxuMQvw9a?dl=0

There are six videos and each corresponds to one of the six activities. In each of the videos, the estimated gazes (i.e., the green circle) and the images of the pupils are overlaid with the user's field-of-view in real-time. 

## DesktopActivity dataset
The dataset will be made publicly available later.


